{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Ultimate Dictionary ***\n",
        "PreMade Algorithm Models"
      ],
      "metadata": {
        "id": "JiGOd0NTpMpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression\n"
      ],
      "metadata": {
        "id": "lZOdbhABpTvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsclMcG5oeTo"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = regressor.predict(X_train)\n",
        "\n",
        "mse = mean_squared_error(y_train, y_train_pred)\n",
        "r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training MSE:\", mse)\n",
        "print(\"Training R²:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LinearRegression(\n",
        "    fit_intercept=True,\n",
        "    normalize=False,  # Deprecated in future versions\n",
        "    copy_X=True,\n",
        "    n_jobs=-1  # Use all processors\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aD88qhStqck6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "UGLs5GAUph9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = logistic_model.predict(X_train)\n",
        "\n",
        "print(\"Coefficients:\", logistic_model.coef_)\n",
        "print(\"Intercept:\", logistic_model.intercept_)"
      ],
      "metadata": {
        "id": "Jzxv0LvHpk-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "LogisticRegression(\n",
        "    penalty='l2',          # L2 regularization\n",
        "    C=1.0,                 # Regularization strength\n",
        "    fit_intercept=True,    # Include intercept\n",
        "    solver='lbfgs',        # Optimization algorithm\n",
        "    max_iter=200,          # Increase iterations\n",
        "    random_state=42,       # For reproducibility\n",
        "    class_weight='balanced'  # Handle class imbalance\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "kspwB2QMqoTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Regression\n"
      ],
      "metadata": {
        "id": "siFfHJGlqMLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is not a separate regression model but involves transforming the input features into polynomial features and then applying linear regression.\n",
        "\n",
        "Scikit-learn provides PolynomialFeatures from sklearn.preprocessing to generate polynomial features. Here's how to implement it with and without parameters:"
      ],
      "metadata": {
        "id": "TEwh0pwir8wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model = Pipeline([\n",
        "    (\"polynomial_features\", PolynomialFeatures()),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "\n",
        "print(\"Coefficients:\", model.named_steps[\"linear_regression\"].coef_)\n",
        "print(\"Intercept:\", model.named_steps[\"linear_regression\"].intercept_)"
      ],
      "metadata": {
        "id": "Q936OBCSqJd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StepWise Regression"
      ],
      "metadata": {
        "id": "oU38fuDJrWtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stepwise regression is not directly implemented in scikit-learn, but it can be performed programmatically by iteratively adding or removing features based on some criteria (e.g., p-values, adjusted R², AIC, or BIC). Below are examples of how to perform stepwise regression, both without and with custom parameters."
      ],
      "metadata": {
        "id": "qfe7N67cr5bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "remaining_features = list(range(X_train.shape[1]))\n",
        "selected_features = []\n",
        "best_adj_r2 = -np.inf\n",
        "\n",
        "while remaining_features:\n",
        "    adj_r2_values = []\n",
        "    for feature in remaining_features:\n",
        "        # Try adding each remaining feature to the selected features\n",
        "        current_features = selected_features + [feature]\n",
        "        X_subset = X_train[:, current_features]\n",
        "        model = sm.OLS(y_train, sm.add_constant(X_subset)).fit()\n",
        "        adj_r2_values.append((model.rsquared_adj, feature))\n",
        "\n",
        "    # Select the feature that improves adjusted R² the most\n",
        "    adj_r2_values.sort(reverse=True, key=lambda x: x[0])\n",
        "    best_candidate, best_feature = adj_r2_values[0]\n",
        "\n",
        "    if best_candidate > best_adj_r2:\n",
        "        best_adj_r2 = best_candidate\n",
        "        selected_features.append(best_feature)\n",
        "        remaining_features.remove(best_feature)\n",
        "    else:\n",
        "        break  # Stop if no improvement\n",
        "\n",
        "\n",
        "X_selected = X_train[:, selected_features]\n",
        "final_model = sm.OLS(y_train, sm.add_constant(X_selected)).fit()\n",
        "\n",
        "print(\"Selected features:\", selected_features)\n",
        "print(final_model.summary())\n"
      ],
      "metadata": {
        "id": "uyJJJEK3rxZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def stepwise_regression(X, y, entry_pvalue=0.05, stay_pvalue=0.05):\n",
        "    initial_features = list(range(X.shape[1]))\n",
        "    selected_features = []\n",
        "    while True:\n",
        "        # Forward step: Add the best feature\n",
        "        remaining_features = list(set(initial_features) - set(selected_features))\n",
        "        new_pvalues = {}\n",
        "        for feature in remaining_features:\n",
        "            model = sm.OLS(y, sm.add_constant(X[:, selected_features + [feature]])).fit()\n",
        "            new_pvalues[feature] = model.pvalues[-1]  # Get p-value for the new feature\n",
        "\n",
        "        if new_pvalues and min(new_pvalues.values()) < entry_pvalue:\n",
        "            best_feature = min(new_pvalues, key=new_pvalues.get)\n",
        "            selected_features.append(best_feature)\n",
        "\n",
        "        # Backward step: Remove the worst feature\n",
        "        model = sm.OLS(y, sm.add_constant(X[:, selected_features])).fit()\n",
        "        pvalues = model.pvalues[1:]  # Exclude intercept\n",
        "        max_pvalue = max(pvalues, default=0)\n",
        "        if max_pvalue > stay_pvalue:\n",
        "            worst_feature = selected_features[pvalues.argmax()]\n",
        "            selected_features.remove(worst_feature)\n",
        "\n",
        "        # Stopping condition\n",
        "        if not new_pvalues or min(new_pvalues.values()) >= entry_pvalue and max_pvalue <= stay_pvalue:\n",
        "            break\n",
        "\n",
        "    final_model = sm.OLS(y, sm.add_constant(X[:, selected_features])).fit()\n",
        "    return final_model, selected_features\n",
        "\n",
        "\n",
        "final_model, selected_features = stepwise_regression(X_train, y_train, entry_pvalue=0.05, stay_pvalue=0.05)\n",
        "print(\"Selected features:\", selected_features)\n",
        "print(final_model.summary())\n"
      ],
      "metadata": {
        "id": "uu6O6tpgsOez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ridge Regression"
      ],
      "metadata": {
        "id": "jaNTAAuTse9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_model = Ridge()\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = ridge_model.predict(X_train)\n",
        "\n",
        "print(\"Coefficients:\", ridge_model.coef_)\n",
        "print(\"Intercept:\", ridge_model.intercept_)"
      ],
      "metadata": {
        "id": "xDURlF7BseWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# ridge_model = Ridge(\n",
        "    alpha=0.5,           # Regularization strength (smaller value = less regularization)\n",
        "    fit_intercept=True,  # Include intercept in the model\n",
        "    solver='saga',       # Use 'saga' solver for large datasets or sparse data\n",
        "    max_iter=1000,       # Maximum number of iterations for optimization\n",
        "    random_state=42      # Seed for reproducibility\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zd0yA6uTsxLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso Regression"
      ],
      "metadata": {
        "id": "OB6ptmiFs27T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso regression is a linear regression model with L1 regularization, which performs feature selection by shrinking some coefficients to exactly zero. Below are examples of how to train a Lasso regression model with and without parameters using scikit-learn."
      ],
      "metadata": {
        "id": "BlwJwNl-tA1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_model = Lasso()\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = lasso_model.predict(X_train)\n",
        "\n",
        "print(\"Coefficients:\", lasso_model.coef_)\n",
        "print(\"Intercept:\", lasso_model.intercept_)"
      ],
      "metadata": {
        "id": "O_lc2FF1tBca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "lasso_model = Lasso(\n",
        "    alpha=0.01,          # Regularization strength (smaller value = less regularization)\n",
        "    fit_intercept=True,  # Include intercept in the model\n",
        "    max_iter=5000,       # Maximum number of iterations for optimization\n",
        "    tol=1e-6,            # Tolerance for stopping criteria\n",
        "    selection='random',  # Random feature selection for faster convergence\n",
        "    random_state=42      # Seed for reproducibility\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DLz3bHJXtIoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Elastic Net Regression"
      ],
      "metadata": {
        "id": "fSZrajeWtbCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elasticnet_model = ElasticNet()\n",
        "elasticnet_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = elasticnet_model.predict(X_train)\n",
        "\n",
        "print(\"Coefficients:\", elasticnet_model.coef_)\n",
        "print(\"Intercept:\", elasticnet_model.intercept_)"
      ],
      "metadata": {
        "id": "qwnO-bsGtJ-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "elasticnet_model = ElasticNet(\n",
        "    alpha=0.01,          # Regularization strength (smaller value = less regularization)\n",
        "    l1_ratio=0.7,        # Proportion of L1 penalty (closer to 1 = more L1 effect)\n",
        "    fit_intercept=True,  # Include intercept in the model\n",
        "    max_iter=5000,       # Maximum number of iterations\n",
        "    tol=1e-6,            # Tolerance for stopping criteria\n",
        "    random_state=42,     # Seed for reproducibility\n",
        "    selection='random'   # Random feature updates for faster convergence\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LGdMr4NvtfEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K Nearest Neighbors"
      ],
      "metadata": {
        "id": "HYfrWFK6tqHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_train)\n",
        "\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "ttSzs7vZt_yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Custom parameters (adjust these as per your needs)\n",
        "n_neighbors = 5  # Number of neighbors to use for prediction\n",
        "metric = 'euclidean'  # Distance metric (e.g., 'euclidean', 'manhattan', etc.)\n",
        "weights = 'uniform'  # Weights to assign to the neighbors (e.g., 'uniform', 'distance')\n",
        "\n",
        "# Initialize the KNN classifier with custom parameters\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric, weights=weights)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gs4vsbCJuJ1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classification"
      ],
      "metadata": {
        "id": "xP3g5bhwuS8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dt_default = DecisionTreeClassifier()\n",
        "dt_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = dt_default.predict(X_train)\n",
        "\n",
        "accuracy_default = accuracy_score(y_train, y_pred_default)\n",
        "print(f\"Decision Tree Training Accuracy: {accuracy_default * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "6ogIgzNxuYLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Custom parameters (adjust as needed)\n",
        "max_depth = 5  # Maximum depth of the tree\n",
        "min_samples_split = 10  # Minimum samples required to split an internal node\n",
        "criterion = 'gini'  # Criterion to measure the quality of a split ('gini' or 'entropy')\n",
        "splitter = 'best'  # Splitting strategy ('best' or 'random')\n",
        "\n",
        "# Initialize the Decision Tree classifier with custom parameters\n",
        "dt_custom = DecisionTreeClassifier(max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split,\n",
        "                                   criterion=criterion,\n",
        "                                   splitter=splitter)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "c4dAvKXsuj5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ],
      "metadata": {
        "id": "2CvGnf1AuqVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "svm_default = SVC()\n",
        "svm_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = svm_default.predict(X_train)\n",
        "\n",
        "accuracy_default = accuracy_score(y_train, y_pred_default)\n",
        "print(f\"Default SVM Training Accuracy: {accuracy_default * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "r9gQ_9evujJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Custom parameters (adjust as needed)\n",
        "kernel = 'rbf'  # Kernel type (options: 'linear', 'poly', 'rbf', 'sigmoid')\n",
        "C = 1.0  # Regularization parameter, larger values prevent overfitting\n",
        "gamma = 'scale'  # Kernel coefficient for 'rbf', 'poly', 'sigmoid' ('scale' or 'auto')\n",
        "degree = 3  # Degree of the polynomial kernel function (if 'poly' kernel is used)\n",
        "\n",
        "# Initialize the SVM classifier with custom parameters\n",
        "svm_custom = SVC(kernel=kernel, C=C, gamma=gamma, degree=degree)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "zsLSCB04u8QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes"
      ],
      "metadata": {
        "id": "qVivnBBXu9tz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "nb_default = GaussianNB()#var_smoothing = 1e-9 is the parameter you can change\n",
        "nb_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = nb_default.predict(X_train)\n",
        "\n",
        "accuracy_default = accuracy_score(y_train, y_pred_default)\n",
        "print(f\"Default Naive Bayes Training Accuracy: {accuracy_default * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "Cuqdpl9uu9bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest"
      ],
      "metadata": {
        "id": "uB42mmZKvZMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_default = RandomForestClassifier()\n",
        "rf_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = rf_default.predict(X_train)\n",
        "\n",
        "accuracy_default = accuracy_score(y_train, y_pred_default)\n",
        "print(f\"Default Random Forest Training Accuracy: {accuracy_default * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "O-oEYBaCvIkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "n_estimators = 100  # Number of trees in the forest\n",
        "max_depth = None  # Maximum depth of the trees\n",
        "min_samples_split = 2  # Minimum number of samples required to split an internal node\n",
        "min_samples_leaf = 1  # Minimum number of samples required to be at a leaf node\n",
        "criterion = 'gini'  # The function to measure the quality of a split ('gini' or 'entropy')\n",
        "\n",
        "# Initialize the Random Forest classifier with custom parameters\n",
        "rf_custom = RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                   max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split,\n",
        "                                   min_samples_leaf=min_samples_leaf,\n",
        "                                   criterion=criterion)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UEpbISg1viwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting"
      ],
      "metadata": {
        "id": "wrYo_xnOvn7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "gb_default = GradientBoostingClassifier()\n",
        "gb_default.fit(X_train, y_train)\n",
        "\n",
        "y_pred_default = gb_default.predict(X_train)\n",
        "\n",
        "accuracy_default = accuracy_score(y_train, y_pred_default)\n",
        "print(f\"Default Gradient Boosting Training Accuracy: {accuracy_default * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "ijkU9kRzvru7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "n_estimators = 100  # Number of boosting stages (trees)\n",
        "learning_rate = 0.1  # Step size used to update the model in each iteration\n",
        "max_depth = 3  # Maximum depth of the individual trees\n",
        "min_samples_split = 2  # Minimum number of samples required to split an internal node\n",
        "subsample = 1.0  # Proportion of samples used for fitting each tree (0.0 to 1.0)\n",
        "loss = 'deviance'  # Loss function to minimize ('deviance' for logistic regression or 'exponential' for AdaBoost)\n",
        "\n",
        "# Initialize the Gradient Boosting classifier with custom parameters\n",
        "gb_custom = GradientBoostingClassifier(n_estimators=n_estimators,\n",
        "                                      learning_rate=learning_rate,\n",
        "                                      max_depth=max_depth,\n",
        "                                      min_samples_split=min_samples_split,\n",
        "                                      subsample=subsample,\n",
        "                                      loss=loss)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ldpSnk1bvzYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging"
      ],
      "metadata": {
        "id": "msIHOX1vv3Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50)\n",
        "bagging.fit(X_train, y_train)\n",
        "y_pred = bagging.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Bagging Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "0Ht4bE5Tv6_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ada Boost"
      ],
      "metadata": {
        "id": "LmUP6MTNwoyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ada_boost = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50)\n",
        "ada_boost.fit(X_train, y_train)\n",
        "y_pred = ada_boost.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"AdaBoost Training Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "GnJxRHccwlyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Model"
      ],
      "metadata": {
        "id": "aD0MHPBnwtpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model1 = LogisticRegression()\n",
        "model2 = SVC()\n",
        "model3 = DecisionTreeClassifier()\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('lr', model1), ('svc', model2), ('dt', model3)], voting='hard')\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred = voting_clf.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Voting Classifier Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "VtAV-ZoPwvYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ExtraTreesClassifier (Extremely Randomized Trees)"
      ],
      "metadata": {
        "id": "VosaBOQuw1Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "et = ExtraTreesClassifier(n_estimators=100, max_depth=10)\n",
        "et.fit(X_train, y_train)\n",
        "y_pred = et.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"ExtraTrees Training Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "jUjWrkDew2wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost"
      ],
      "metadata": {
        "id": "S3wfOHHww4NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred = xgb_model.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"XGBoost Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "AdwhOsfMw91b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LightGBM (Light Gradient Boosting Machine)\n",
        "used for large datasets"
      ],
      "metadata": {
        "id": "9uOXGnPvxBEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "y_pred = lgb_model.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"LightGBM Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "e63RJifGxBtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CatBoost\n",
        "for Categorical Variables"
      ],
      "metadata": {
        "id": "vqxXYUDpxGoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "catboost_model = CatBoostClassifier(iterations=100, learning_rate=0.1)\n",
        "catboost_model.fit(X_train, y_train)\n",
        "y_pred = catboost_model.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"CatBoost Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "dqDl_twaxIwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks (MLPClassifier)\n",
        "A multi-layer perceptron (MLP) neural network classifier for non-linear decision boundaries."
      ],
      "metadata": {
        "id": "IRqm4200xOvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"MLP Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "FZ8hYozOxWaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SGD Classifier (Stochastic Gradient Descent)"
      ],
      "metadata": {
        "id": "_zG03heHxYYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sgd = SGDClassifier(max_iter=1000)\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred = sgd.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"SGD Classifier Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "S2mAKkOrxhbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perceptron"
      ],
      "metadata": {
        "id": "DyG0OBshxkRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "perceptron = Perceptron()\n",
        "perceptron.fit(X_train, y_train)\n",
        "y_pred = perceptron.predict(X_train)\n",
        "accuracy = accuracy_score(y_train, y_pred)\n",
        "print(f\"Perceptron Training Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "ib1vEJw8xnAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dimensionality Reduction Methods"
      ],
      "metadata": {
        "id": "azQ3f_BOx3zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "TkUbY7qbxqbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X_train)\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)"
      ],
      "metadata": {
        "id": "cTA3kKQhxxPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-Distributed Stochastic Neighbor Embedding (t-SNE)"
      ],
      "metadata": {
        "id": "x7OfxjBbxzxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_tsne = TSNE(n_components=2).fit_transform(X_train)"
      ],
      "metadata": {
        "id": "xG0pAv-gyBlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Discriminant Analysis (LDA)"
      ],
      "metadata": {
        "id": "AapaQpeTyArj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_lda = lda.fit_transform(X_train, y_train)"
      ],
      "metadata": {
        "id": "RdADtNdKyG4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Independent Component Analysis (ICA)\n",
        "Similar to PCA, but finds statistically independent components rather than uncorrelated ones."
      ],
      "metadata": {
        "id": "lv7smgR7yI_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import FastICA\n",
        "ica = FastICA(n_components=2)\n",
        "X_ica = ica.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "FE380bApyR7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation and Selection"
      ],
      "metadata": {
        "id": "TLenjReRyTu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross-Validation (KFold, StratifiedKFold)"
      ],
      "metadata": {
        "id": "V-Dk4BjuycCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(ridge_clf, X_train, y_train, cv=5)\n",
        "print(f\"Cross-validation scores: {scores}\")"
      ],
      "metadata": {
        "id": "G9Pm0JEwyZkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid Search (Hyperparameter Tuning)"
      ],
      "metadata": {
        "id": "WtXZ8IZXyhcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "id": "AtwH1rqMyj4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Randomized Search (Hyperparameter Tuning)"
      ],
      "metadata": {
        "id": "M6eTPcZXymQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_dist = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "random_search = RandomizedSearchCV(SVC(), param_dist, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {random_search.best_params_}\")"
      ],
      "metadata": {
        "id": "CJYrDnFOyoYa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}